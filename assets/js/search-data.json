{
  
    
        "post0": {
            "title": "",
            "content": "My plunge into deep learning . Two years ago, I was getting close to the end of my astrophysics PhD program. I had always been interested in statistical methods and machine learning, but never made the leap into deep learning territory. Andrew Ng&#39;s legendary machine learning course was an excellent introduction to building simple neural networks from scratch, but I wasn&#39;t sure what to do next. What I really needed was an astrophysics research project! . Around this time, I was fortunate enough to hear about the Fast.ai &quot;Practical Deep Learning for Coders&quot; (2018) course, which introduced deep learning using a top-down approach. The course also served as a guide for using the Fastai codebase, which is built atop Pytorch. I also noticed that some Fastai users were interested in applying their knowledge to the Kaggle GalaxyZoo classification challenge, which used galaxy image cutouts as their primary source of data. Since I was already interested in galaxy evolution, it seemed like a good idea to think about the types of problems that could be solved using similar data sets. . With the right tools in hand, I teamed up with a postdoc, Steven Boada, and began working on my first deep learning project... . The problem: measuring metallicity takes up a lot of telescope time! . We see galaxies as gravitationally bound collections of stars, gas, and dust. Galaxies grow by forming new stars out of cold gas, most of which is hydrogen, the lightest and most abundant element in the Universe. Over the course of the stars&#39; lifetimes, heavy elements are fused and eventually strewn across the galaxy through a combination of stellar winds and supernova explosions. Since heavy elements can only be produced inside stars, the ratio of heavy-to-light element abundances is a key measurable for understanding the galaxy&#39;s history of star formation and gas accretion. This abundance ratio of heavy-to-light elements is known as the metallicity. Galaxies which have formed more stars tend to also have higher metallicity. . . This galaxy, NGC 99, is a nearby star-forming spiral galaxy. Its blue color indicates the presence of newly formed stars, which burn brightly but haven&#39;t lived long enough to expel lots of heavy elements into the their surroundings. For this reason, we might expect NGC 99 to be relatively low in metallicity. . . NGC 936 is a redder galaxy, signifying that it has not formed any new stars for a while. Nearly all of its massive, short-lived stars have fused heavy elements and dispersed them throughout the interstellar medium. It does not appear that any pristine, mostly hydrogen (i.e., low-metallicity) gas has recently accreted into the galaxy -- since that would trigger a round of star formation marked by bright blue stars -- so we can infer that this galaxy has fairly high metallicity. . Metallicity does a great job of summarizing a galaxy&#39;s evolutionary history, but it&#39;s not so easy to measure. Typically, astronomers measure the ratio of oxygen to hydrogen atoms in a galaxy, and spectroscopic observations are required for inferring these elemental abundances. Spectroscopy takes much more time than imaging, and is not as easy to do for many objects at once! . Making the most of pretty galaxy pictures . The physical processes that determine a galaxy&#39;s metallicity also leave imprints on the galaxy&#39;s morphology. The structure and color of a galaxy provide us with a rich description of its growth and evolution. Thus, it would make sense that image cutouts might contain enough information for estimating a galaxy&#39;s metallicity. . We train a deep convolutional neural network (CNN) to predict the metallicity directly from imaging. The images are queried from the Sloan Digital Sky Survey (SDSS) SkyServer in JPG format, and consisted of $128 times 128$ pixel images in three colors ($i$, $r$, and $g$ bands corresponding to RGB channels). All in all, we grab about 130,000 galaxy images, and set aside approximately 60% for training, 20% for validation, and 20% for testing. . After only 30 minutes of training on a single GPU, we were able to predict the metallicity of any given galaxy to within 0.085 dex (root mean squared error). This means that our hunch was correct: galaxy images are enough for accurately estimating their metallicities! . . In the figure above, $Z$ represents metallicity, and $Z_{ rm pred}$ and $Z_{ rm true}$ are the CNN-predicted and spectroscopic metallicties, respectively. We are showing a few low-metallicity galaxies (top row), high-metallicity galaxies (middle row), and randomly selected galaxies. We find that our previous intuitions are confirmed! This figure is a simplified version of one that can be found in our published paper (Wu &amp; Boada 2019). . Morphology, mass, and metallicity . As we have discussed, it is well-known that galaxies&#39; star formation and chemical evolution histories are connected. Previous astronomers have measured a strong correlation between the stellar masses and metallicities of galaxies (forming the so-called mass-metallicity relation, or MZR). Although it is observationally difficult to measure the metallicities of other galaxies, it is easy to measure their stellar masses. So how do we know that the neural network isn&#39;t learning the galaxies&#39; stellar masses, and simply converting these into metallicities via the MZR? . We decided to investigate the relationship between galaxy masses and metallicities measured two ways. The original MZR is constructed from observed metallicities (shown in black below), and we also use CNN-predicted metallicities (shown in red below) to reconstruct the MZR. . . The two versions of the MZR are extremely similar! Both the CNN predictions and the optical spectroscopy give metallicities that correlate with stellar mass to within 0.10 dex (i.e., extremely tight scatter). But the optical spectroscopy served as the ground truth for our CNN, so how could it be that the CNN predictions do not add even a little extra scatter into this original relationship? . It appears that the CNN is using morphological information to characterize galaxies in a way that explains some of the variance in the MZR. In other words, the MZR does not represent the intrinsic scatter due to the physics of galaxy formation and evolution; rather, some of this scatter can be reduced by using other information such as the morphology. (Another possibility is that the galaxy&#39;s star formation rate explains some of the scatter, and that we are instead leveraging this information, but this is unlikely given the fact that we do not study the blue/ultraviolet light from these galaxies.) . Summary . In our paper, which was published in Monthly Notices of the Royal Astronomical Society and can be found on NASA ADS and arXiv, we trained a CNN to predict the metallicity directly from optical-wavelength images. The results were far better than we could have imagined at first: we could accurately estimate the metallicity to within 0.085 dex, and we found that the reconstructed mass-metallicity relationship using CNN predictions had extremely narrow scatter (0.10 dex). . These findings imply that morphological information is essential for understanding how galaxies grow and evolve. Although classification systems and simple parameterizations of their morphological features are useful for encoding this information, they are not nearly as flexible as CNNs. . If you&#39;re interested in seeing some of the more technical details, then please stay tuned for my next post! I&#39;ll be showcasing some of the analysis, updated using the Fastai v2 codebase. Otherwise, take a look at the original Github repository for the paper, or a demo version of the code (which includes a small subset of the data). .",
            "url": "https://jwuphysics.github.io/blog/2020/05/21/2020-05-21-exploring-galaxies-with-deep-learning.html",
            "relUrl": "/2020/05/21/2020-05-21-exploring-galaxies-with-deep-learning.html",
            "date": " • May 21, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://jwuphysics.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jwuphysics.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jwuphysics.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}